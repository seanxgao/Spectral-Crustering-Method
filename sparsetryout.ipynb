{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31e14144-7e7a-4385-ae82-b1108c636c8b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Benchmark bicut (N = 2000, graphs = 5) ===\n",
      "solvers: dense, sparse\n",
      "\n",
      "solver   | avg time (s) | std (s)\n",
      "----------------------------------\n",
      "dense   | 0.6246       | 0.0102\n",
      "sparse  | 0.4539       | 0.0133\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from typing import Tuple, List, Dict\n",
    "\n",
    "from scipy import sparse as sp\n",
    "from scipy.linalg import eigh          # dense solver\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import eigsh  # sparse solver\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Graph generator (reproducible)\n",
    "# -----------------------------\n",
    "def generate_layers_groups_graph(\n",
    "    num_supergroups: int = 2,\n",
    "    num_subgroups_per_supergroup: int = 2,\n",
    "    nodes_per_subgroup: int = 5,\n",
    "    p_intra_subgroup: float = 0.8,\n",
    "    p_intra_supergroup: float = 0.3,\n",
    "    p_inter_supergroup: float = 0.05,\n",
    "    seed: int | None = 841,    # global seed for reproducibility (None => random)\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Generate hierarchical Laplacian L (dense, float64).\"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    nsg, nps = num_subgroups_per_supergroup, nodes_per_subgroup\n",
    "    N = num_supergroups * nsg * nps\n",
    "    A = np.zeros((N, N), dtype=np.uint8)\n",
    "\n",
    "    def idx(g, sg, k):\n",
    "        return (g * nsg + sg) * nps + k\n",
    "\n",
    "    # Intra-supergroup\n",
    "    for g in range(num_supergroups):\n",
    "        for sg1 in range(nsg):\n",
    "            # same subgroup\n",
    "            for k1 in range(nps):\n",
    "                i = idx(g, sg1, k1)\n",
    "                for k2 in range(k1 + 1, nps):\n",
    "                    j = idx(g, sg1, k2)\n",
    "                    if np.random.rand() < p_intra_subgroup:\n",
    "                        A[i, j] = A[j, i] = 1\n",
    "            # different subgroups in same supergroup\n",
    "            for sg2 in range(sg1 + 1, nsg):\n",
    "                for k1 in range(nps):\n",
    "                    i = idx(g, sg1, k1)\n",
    "                    for k2 in range(nps):\n",
    "                        j = idx(g, sg2, k2)\n",
    "                        if np.random.rand() < p_intra_supergroup:\n",
    "                            A[i, j] = A[j, i] = 1\n",
    "\n",
    "    # Inter-supergroup\n",
    "    for g1 in range(num_supergroups):\n",
    "        for g2 in range(g1 + 1, num_supergroups):\n",
    "            for sg1 in range(nsg):\n",
    "                for sg2 in range(nsg):\n",
    "                    for k1 in range(nps):\n",
    "                        i = idx(g1, sg1, k1)\n",
    "                        for k2 in range(nps):\n",
    "                            j = idx(g2, sg2, k2)\n",
    "                            if np.random.rand() < p_inter_supergroup:\n",
    "                                A[i, j] = A[j, i] = 1\n",
    "\n",
    "    deg = A.sum(axis=1, dtype=np.int64).astype(np.float64)\n",
    "    L = np.diag(deg) - A.astype(np.float64)\n",
    "    return L\n",
    "\n",
    "\n",
    "# -----------------------------------------\n",
    "# Fiedler vector by dense or sparse backend\n",
    "# -----------------------------------------\n",
    "def _fiedler_vector(L, solver: str = \"sparse\") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Return Fiedler vector of Laplacian L using:\n",
    "      - solver='dense'  -> scipy.linalg.eigh (subset_by_index)\n",
    "      - solver='sparse' -> scipy.sparse.linalg.eigsh\n",
    "    L can be dense ndarray or sparse CSR; we normalize as needed.\n",
    "    \"\"\"\n",
    "    if solver not in (\"dense\", \"sparse\"):\n",
    "        raise ValueError(\"solver must be 'dense' or 'sparse'.\")\n",
    "\n",
    "    n = L.shape[0]\n",
    "\n",
    "    if solver == \"dense\":\n",
    "        # Convert to dense (if sparse), then compute the two smallest eigenpairs\n",
    "        A = L.toarray() if sp.issparse(L) else L\n",
    "        # eigh with subset_by_index avoids full spectrum\n",
    "        # Note: check_finite=False for speed (assumes inputs are finite)\n",
    "        w, v = eigh(A, subset_by_index=[0, 1], check_finite=False, overwrite_a=False)\n",
    "        return v[:, 1]\n",
    "\n",
    "    # sparse:\n",
    "    Lsp = L if sp.issparse(L) else csr_matrix(L)\n",
    "    # float32 often suffices and is faster; switch to float64 if convergence issues\n",
    "    Lsp = Lsp.astype(np.float32)\n",
    "    vals, vecs = eigsh(Lsp, k=2, which='SA')\n",
    "    return vecs[:, 1]\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# bicut (with solver choice)\n",
    "# ---------------------------\n",
    "def bicut_group(L, solver: str = \"sparse\") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Your original bicut, but with a 'solver' switch for dense/sparse eigen solve.\n",
    "    Returns local index lists (first_group, second_group).\n",
    "    \"\"\"\n",
    "    n = L.shape[0]\n",
    "    if n == 0:\n",
    "        raise ValueError(\"The Laplacian matrix is empty.\")\n",
    "    if n == 1:\n",
    "        return np.array([0]), np.array([])\n",
    "    if n == 2:\n",
    "        return np.array([0]), np.array([1])\n",
    "\n",
    "    # 1) Fiedler vector and sorting\n",
    "    fiedler = _fiedler_vector(L, solver=solver)\n",
    "    order = np.argsort(fiedler)\n",
    "\n",
    "    # 2) Build adjacency in the ordered space and scan best cut\n",
    "    # A = -L_off; we just reuse your dense scanning logic\n",
    "    if sp.issparse(L):\n",
    "        A_perm = (-L)[order][:, order].toarray()\n",
    "    else:\n",
    "        A_perm = (-L)[np.ix_(order, order)]\n",
    "\n",
    "    ind = np.arange(1, n)\n",
    "    upper_tri_sums = np.array([A_perm[i:, :i].sum() for i in ind], dtype=float)\n",
    "    qualities = upper_tri_sums / (ind * (n - ind))\n",
    "    best_cut = int(np.argmin(qualities) + 1)\n",
    "\n",
    "    g1 = order[:best_cut]\n",
    "    g2 = order[best_cut:]\n",
    "    # Keep vertex 0 in the first group as you did\n",
    "    return (g1, g2) if 0 in g1 else (g2, g1)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Simple benchmark harness\n",
    "# ---------------------------\n",
    "def benchmark_bicut(\n",
    "    num_graphs: int = 5,\n",
    "    sup: int = 10, sub: int = 10, node: int = 10,  # 10*10*10 = 1000\n",
    "    p_intra_subgroup: float = 0.8,\n",
    "    p_intra_supergroup: float = 0.3,\n",
    "    p_inter_supergroup: float = 0.05,\n",
    "    solvers: Tuple[str, ...] = (\"dense\", \"sparse\"),\n",
    "    seed_base: int = 1000,\n",
    "    warmup: bool = True,\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Generate several graphs of size sup*sub*node, and time bicut_group with\n",
    "    different solvers. Returns a list of result dicts and prints a small table.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    print(f\"\\n=== Benchmark bicut (N = {sup*sub*node}, graphs = {num_graphs}) ===\")\n",
    "    print(f\"solvers: {', '.join(solvers)}\\n\")\n",
    "\n",
    "    # Pre-generate graphs (same graphs for all solvers)\n",
    "    graphs = []\n",
    "    for i in range(num_graphs):\n",
    "        seed = seed_base + i\n",
    "        L = generate_layers_groups_graph(\n",
    "            num_supergroups=sup,\n",
    "            num_subgroups_per_supergroup=sub,\n",
    "            nodes_per_subgroup=node,\n",
    "            p_intra_subgroup=p_intra_subgroup,\n",
    "            p_intra_supergroup=p_intra_supergroup,\n",
    "            p_inter_supergroup=p_inter_supergroup,\n",
    "            seed=seed,\n",
    "        )\n",
    "        graphs.append(L)\n",
    "\n",
    "    # Optional warmup to avoid JIT/caches affecting first timing\n",
    "    if warmup:\n",
    "        _ = bicut_group(graphs[0], solver=\"dense\")\n",
    "        _ = bicut_group(graphs[0], solver=\"sparse\")\n",
    "\n",
    "    # Time each solver on all graphs\n",
    "    for solver in solvers:\n",
    "        times = []\n",
    "        for i, L in enumerate(graphs):\n",
    "            t0 = time.perf_counter()\n",
    "            _ = bicut_group(L, solver=solver)\n",
    "            dt = time.perf_counter() - t0\n",
    "            times.append(dt)\n",
    "        avg = float(np.mean(times))\n",
    "        std = float(np.std(times))\n",
    "        results.append({\"solver\": solver, \"avg_s\": avg, \"std_s\": std})\n",
    "\n",
    "    # Pretty print\n",
    "    print(\"solver   | avg time (s) | std (s)\")\n",
    "    print(\"----------------------------------\")\n",
    "    for r in results:\n",
    "        print(f\"{r['solver']:<8}| {r['avg_s']:.4f}       | {r['std_s']:.4f}\")\n",
    "    print()\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Example usage\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Case 1: ~1000 x 1000 (10*10*10)\n",
    "    benchmark_bicut(num_graphs=5, sup=1, sub=100, node=20, solvers=(\"dense\", \"sparse\"))\n",
    "\n",
    "    # You can scale up easily, e.g. ~ 2744 x 2744 (14*14*14)\n",
    "    # benchmark_bicut(num_graphs=3, sup=14, sub=14, node=14, solvers=(\"dense\", \"sparse\"))\n",
    "\n",
    "    # Or make it bigger and sparser by lowering probabilities:\n",
    "    # benchmark_bicut(num_graphs=3, sup=20, sub=20, node=10,\n",
    "    #                 p_intra_subgroup=0.4, p_intra_supergroup=0.05, p_inter_supergroup=0.01,\n",
    "    #                 solvers=(\"dense\", \"sparse\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea0ca13-bc5c-415e-b744-5a0582a268e3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab24994a-3773-4907-aac9-cc738414356c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f6c743e-1661-4822-a8f8-de9c5864e6ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tests import *\n",
    "\n",
    "test_bicut_accuracy(1000,1000,0.8,0.7,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e8337b6-497e-49ab-9d29-2b88f399b907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'duration': 0.6040008068084717,\n",
       " 'memory': 8.014852523803711,\n",
       " 'ratio': 1.1407710571733556}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tests import *\n",
    "\n",
    "run_one_graph_test(1,10,20,1,False,\"dense\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b24931-046a-41f5-bf6b-b398fa0408a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
